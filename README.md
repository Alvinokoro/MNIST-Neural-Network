# MNIST-Neural-Network

This repository contains a deep learning project where I classify handwritten digits from the MNIST dataset using TensorFlow/Keras. I experiment with various neural network architectures, including simple and complex deep networks, with and without regularization.

Project Overview

The MNIST dataset is a collection of handwritten digits (0-9) that is widely used in the machine learning community. The goal of this project is to build and evaluate different neural network models to classify these digits. I preprocess the data, create multiple neural network architectures, evaluate model performance, and visualize the results.

Key Features:

Data Preprocessing: Data normalization, reshaping, and splitting into training, validation, and test sets.
Model Architecture: Implementation of several deep neural network architectures with varying numbers of hidden layers and units.

Regularization: Introduction of L1 regularization to prevent overfitting.
Model Evaluation: Training and validation loss plotting, confusion matrix, and sample predictions.

Visualization: Visualizing the confusion matrix and predictions on test samples.

Tools & Libraries Used:

TensorFlow/Keras: For building and training the neural network models.

NumPy: For numerical operations.

Matplotlib: For data visualization and plotting training/validation history.

Seaborn: For visualizing the confusion matrix.

scikit-learn: For splitting the dataset and computing confusion matrix.

Prerequisites:
Before running the code, ensure that you have installed the necessary libraries:

